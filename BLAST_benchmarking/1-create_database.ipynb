{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This the benchmarking against blast. We test the accuracy of blast in predicting the transporter (to compare to our classification model) by running a sequence against the database of the training dataset and seeing if the highest similarity sequence is a transporter or not. If the highest similarity sequence in the training dataset is a transport, we classify the input sequence as a transporter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the function of the function that takes an input sequence and compares it all sequences in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/sshafaei1/.conda/envs/newmain/lib/python3.10/site-packages/Bio/Application/__init__.py:39: BiopythonDeprecationWarning: The Bio.Application modules and modules relying on it have been deprecated.\n",
      "\n",
      "Due to the on going maintenance burden of keeping command line application\n",
      "wrappers up to date, we have decided to deprecate and eventually remove these\n",
      "modules.\n",
      "\n",
      "We instead now recommend building your command line and invoking it directly\n",
      "with the subprocess module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Bio import Blast\n",
    "from Bio import SeqIO\n",
    "from Bio.Blast.Applications import NcbimakeblastdbCommandline, NcbiblastnCommandline, NcbiblastpCommandline \n",
    "from Bio.Blast import NCBIXML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load in the training dataset as reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117766\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>output</th>\n",
       "      <th>ankh_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MENLDEVQWRSPEWIQAHQGLRTDNVLDYFAESPFYDRVSNNQVLR...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.018960073590278625, 0.0004224804579280317, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Sequence  output  \\\n",
       "0           0  MENLDEVQWRSPEWIQAHQGLRTDNVLDYFAESPFYDRVSNNQVLR...       0   \n",
       "\n",
       "                                          ankh_large  \n",
       "0  [0.018960073590278625, 0.0004224804579280317, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_data = pd.read_csv(\"./dataset/final_training.csv\")\n",
    "print(len(ref_data))\n",
    "ref_data.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>output</th>\n",
       "      <th>ankh_large</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MENLDEVQWRSPEWIQAHQGLRTDNVLDYFAESPFYDRVSNNQVLR...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.018960073590278625, 0.0004224804579280317, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Sequence  output  \\\n",
       "0           0  MENLDEVQWRSPEWIQAHQGLRTDNVLDYFAESPFYDRVSNNQVLR...       0   \n",
       "\n",
       "                                          ankh_large  id  \n",
       "0  [0.018960073590278625, 0.0004224804579280317, ...   0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_data[\"id\"] = list(range(0,len(ref_data)))\n",
    "ref_data.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating the database, first create a fasta file, then merge it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(\"./training.fasta\",\"w\")\n",
    "for i, row in ref_data.iterrows():\n",
    "    #get current sequence entry code, with the classification output\n",
    "    true_class = row[\"output\"]#real classification\n",
    "    entry = row[\"id\"]\n",
    "    seq = row[\"Sequence\"]\n",
    "    f.write(f\">{entry}-{str(true_class)}\\n\")#write the heading name includes true classification as a -\n",
    "    f.write(f\"{seq}\\n\") #write the sequence\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the blast db file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 04/11/2025 00:43:37\n",
      "New DB name:   /work/hdd/bcij/sshafaei1/Transporter_Protein_project/Transporter_classification_model_3/Blast_benchmarking/my_protein_db\n",
      "New DB title:  training.fasta\n",
      "Sequence type: Protein\n",
      "Deleted existing Protein BLAST database named /work/hdd/bcij/sshafaei1/Transporter_Protein_project/Transporter_classification_model_3/Blast_benchmarking/my_protein_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 3000000000B\n",
      "Adding sequences from FASTA; added 117766 sequences in 14.2132 seconds.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['makeblastdb', '-in', 'training.fasta', '-dbtype', 'prot', '-out', 'my_protein_db'], returncode=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\n",
    "    \"makeblastdb\",\n",
    "    \"-in\", \"training.fasta\",\n",
    "    \"-dbtype\", \"prot\",\n",
    "    \"-out\", \"my_protein_db\"\n",
    "], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing running test data\n",
    "\n",
    "running on test data(mostly run on cluster, testing here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26282\n"
     ]
    }
   ],
   "source": [
    "input_data = pd.read_csv(\"./dataset/final_testing.csv\")\n",
    "input_data[\"id\"] = list(range(0,len(input_data))) #add id column\n",
    "\n",
    "print(len(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: 0\n",
      "No significant matches found.\n",
      "predicted: 0\n",
      "No significant matches found.\n",
      "No significant matches found.\n",
      "predicted: 1\n",
      "predicted: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f= open(\"./outputs.csv\",\"w\") #create a file file to store outputs\n",
    "f.write(\"seq,true,predicted\\n\") #write header\n",
    "for i, row in input_data.iterrows():\n",
    "    if i > 6: break\n",
    "    #get current sequence entry code, with the classification output\n",
    "    true_class = row[\"output\"]#real classification\n",
    "    entry = row[\"id\"]\n",
    "    seq = row[\"Sequence\"]\n",
    "    #create a single query fasta\n",
    "    q = open(\"./query.fasta\",\"w\")\n",
    "    q.write(\">test\\n\")\n",
    "    q.write(f\"{seq}\\n\") \n",
    "    q.close()\n",
    "\n",
    "    #run a blast search\n",
    "    blastp_cline = NcbiblastpCommandline(\n",
    "        query=\"query.fasta\", \n",
    "        db=\"my_protein_db\", \n",
    "        evalue=0.001, \n",
    "        outfmt=5,  # XML format\n",
    "        out=\"results.xml\"\n",
    "    )\n",
    "    stdout, stderr = blastp_cline()\n",
    "    if stderr:\n",
    "        subprocess.run([\"echo\", f\"error: {stderr}\"])\n",
    "    #Parse BLAST Results\n",
    "    with open(\"results.xml\") as result_handle:\n",
    "        blast_record = NCBIXML.read(result_handle)\n",
    "\n",
    "    # Step 5: Get Most Similar Sequence\n",
    "    predicted_class = 0\n",
    "    try:\n",
    "        best_match = blast_record.alignments[0]  # Top hit\n",
    "        predicted_class = str(best_match.title).split(\"-\")[1]\n",
    "        subprocess.run([\"echo\", f\"predicted: {predicted_class}\"])\n",
    "    except:\n",
    "        subprocess.run([\"echo\", \"No significant matches found.\"])\n",
    "        continue\n",
    "\n",
    "    f.write(f\"{seq},{true_class},{predicted_class}\\n\")#write rows to the csv\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newmain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
